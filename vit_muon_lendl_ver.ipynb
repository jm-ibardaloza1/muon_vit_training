{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AmD3rp3levFI"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.vision_transformer import VisionTransformer\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNy-sQ6pfYqK",
        "outputId": "a3883054-fdae-45b7-f0d3-763d26506489"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 64"
      ],
      "metadata": {
        "id": "mkAyKuBvf8xI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = (0.5071, 0.4867, 0.4408)\n",
        "std = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.CenterCrop(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train = CIFAR100(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
        "test  = CIFAR100(root=\"./data\", train=False, download=True, transform=test_transforms)"
      ],
      "metadata": {
        "id": "2yLZ8r-7gcwi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")"
      ],
      "metadata": {
        "id": "ntXoSlHKflbT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "zA8K5gvQhdJH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_top1(logits, targets):\n",
        "  preds = logits.argmax(dim=1)\n",
        "  return (preds == targets).float().mean().item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "  model.eval()\n",
        "  total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "  for x, y in loader:\n",
        "    x = x.to(device, non_blocking=True)\n",
        "    y = y.to(device, non_blocking=True)\n",
        "    logits = model(x)\n",
        "    loss = criterion(logits, y)\n",
        "    bs = x.size(0)\n",
        "    total_loss += loss.item() * bs\n",
        "    total_acc  += accuracy_top1(logits, y) * bs\n",
        "    n += bs\n",
        "  return total_loss / n, total_acc / n"
      ],
      "metadata": {
        "id": "01n7-bx6hdhD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AdamW"
      ],
      "metadata": {
        "id": "EHfynxqvkzRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 20\n",
        "LR_ADAMW = 2e-4\n",
        "WD_ADAMW = 0.05"
      ],
      "metadata": {
        "id": "xWkHEiiu4g0R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionTransformer(\n",
        "  image_size=IMAGE_SIZE,\n",
        "  patch_size=8, # 64 / 8 = 8 patches per side -> 64 tokens\n",
        "  num_layers=12,\n",
        "  num_heads=6,\n",
        "  hidden_dim=384,\n",
        "  mlp_dim=1536,\n",
        "  dropout=0.1,\n",
        "  attention_dropout=0.1,\n",
        "  num_classes=100\n",
        ")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Ho2w5Afm8LdJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(\n",
        "  model.parameters(),\n",
        "  lr=LR_ADAMW,\n",
        "  weight_decay=WD_ADAMW\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "scaler = torch.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7MuQYEMv8BUp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch_adamw(model, loader, optimizer, scaler, criterion):\n",
        "  model.train()\n",
        "  total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "\n",
        "  for x, y in loader:\n",
        "    x = x.to(device, non_blocking=True)\n",
        "    y = y.to(device, non_blocking=True)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    with torch.autocast(device_type=device, dtype=torch.float16, enabled=(device==\"cuda\")):\n",
        "      logits = model(x)\n",
        "      loss = criterion(logits, y)\n",
        "\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    bs = x.size(0)\n",
        "    total_loss += loss.item() * bs\n",
        "    total_acc  += accuracy_top1(logits, y) * bs\n",
        "    n += bs\n",
        "\n",
        "  return total_loss / n, total_acc / n"
      ],
      "metadata": {
        "id": "5-z9IZ-t7FiH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "patience = 5   # Stop after 5 epochs w/ no meaningful improvement\n",
        "bad_epochs = 0\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  train_loss, train_acc = train_one_epoch_adamw(\n",
        "      model,\n",
        "      train_loader,\n",
        "      optimizer,\n",
        "      scaler,\n",
        "      criterion\n",
        "    )\n",
        "  test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "  scheduler.step()\n",
        "\n",
        "  print(f\"Epoch {epoch} | \"\n",
        "        f\"Train Loss {train_loss:.4f}, Accuracy {train_acc:.4f} | \"\n",
        "        f\"Test Loss {test_loss:.4f}, Accuracy {test_acc:.4f}\")\n",
        "\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    bad_epochs = 0\n",
        "    torch.save(model.state_dict(), \"vit_cifar100_best_adamw.pt\")\n",
        "  else:\n",
        "    bad_epochs += 1\n",
        "    if bad_epochs >= patience:\n",
        "      print(f\"Early stopping at epoch {epoch}. Best Test Accuracy: {best_acc:.4f}\")\n",
        "      break\n",
        "\n",
        "print(\"Best Test Accuracy:\", best_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B-OuIHEhjmf",
        "outputId": "fec7dbef-7901-4a5f-f7ba-cab4415db1b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss 4.0831, Accuracy 0.0710 | Test Loss 3.8104, Accuracy 0.1079\n",
            "Epoch 2 | Train Loss 3.6246, Accuracy 0.1345 | Test Loss 3.5032, Accuracy 0.1583\n",
            "Epoch 3 | Train Loss 3.3302, Accuracy 0.1890 | Test Loss 3.2359, Accuracy 0.2054\n",
            "Epoch 4 | Train Loss 3.0717, Accuracy 0.2354 | Test Loss 2.9889, Accuracy 0.2453\n",
            "Epoch 5 | Train Loss 2.8623, Accuracy 0.2731 | Test Loss 2.8160, Accuracy 0.2867\n",
            "Epoch 6 | Train Loss 2.7059, Accuracy 0.3057 | Test Loss 2.6766, Accuracy 0.3154\n",
            "Epoch 7 | Train Loss 2.5726, Accuracy 0.3339 | Test Loss 2.5676, Accuracy 0.3374\n",
            "Epoch 8 | Train Loss 2.4503, Accuracy 0.3549 | Test Loss 2.4383, Accuracy 0.3585\n",
            "Epoch 9 | Train Loss 2.3329, Accuracy 0.3825 | Test Loss 2.3701, Accuracy 0.3815\n",
            "Epoch 10 | Train Loss 2.2301, Accuracy 0.4046 | Test Loss 2.3095, Accuracy 0.3964\n",
            "Epoch 11 | Train Loss 2.1396, Accuracy 0.4241 | Test Loss 2.2120, Accuracy 0.4183\n",
            "Epoch 12 | Train Loss 2.0406, Accuracy 0.4471 | Test Loss 2.1567, Accuracy 0.4323\n",
            "Epoch 13 | Train Loss 1.9553, Accuracy 0.4685 | Test Loss 2.1340, Accuracy 0.4379\n",
            "Epoch 14 | Train Loss 1.8734, Accuracy 0.4876 | Test Loss 2.0778, Accuracy 0.4458\n",
            "Epoch 15 | Train Loss 1.8033, Accuracy 0.5031 | Test Loss 2.0451, Accuracy 0.4547\n",
            "Epoch 16 | Train Loss 1.7476, Accuracy 0.5169 | Test Loss 2.0249, Accuracy 0.4651\n",
            "Epoch 17 | Train Loss 1.6937, Accuracy 0.5314 | Test Loss 2.0039, Accuracy 0.4668\n",
            "Epoch 18 | Train Loss 1.6582, Accuracy 0.5402 | Test Loss 1.9952, Accuracy 0.4685\n",
            "Epoch 19 | Train Loss 1.6410, Accuracy 0.5431 | Test Loss 1.9892, Accuracy 0.4711\n",
            "Epoch 20 | Train Loss 1.6237, Accuracy 0.5482 | Test Loss 1.9828, Accuracy 0.4717\n",
            "Best Test Accuracy: 0.4717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Muon"
      ],
      "metadata": {
        "id": "F16PHwkU4fe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 20\n",
        "LR_ADAMW = 3e-4\n",
        "WD_ADAMW = 0.05\n",
        "LR_MUON = 3e-4\n",
        "WD_MUON = 0.05\n",
        "MOM_MUON = 0.95"
      ],
      "metadata": {
        "id": "7LLuAepp4hTZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionTransformer(\n",
        "  image_size=IMAGE_SIZE,\n",
        "  patch_size=8, # 64 / 8 = 8 patches per side -> 64 tokens\n",
        "  num_layers=12,\n",
        "  num_heads=6,\n",
        "  hidden_dim=384,\n",
        "  mlp_dim=1536,\n",
        "  dropout=0.1,\n",
        "  attention_dropout=0.1,\n",
        "  num_classes=100\n",
        ")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "HbGy4Gee8NJN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "muon_params = []\n",
        "adamw_params = []\n",
        "for n, p in model.named_parameters():\n",
        "  layer_name = n\n",
        "  if not p.requires_grad:\n",
        "    continue\n",
        "  # Parameters should be 2D and not an output layer\n",
        "  if p.ndim == 2 and \"heads\" not in layer_name:\n",
        "    muon_params.append(p)\n",
        "  else:\n",
        "    adamw_params.append(p)\n",
        "\n",
        "opt_muon = optim.Muon(\n",
        "  muon_params,\n",
        "  lr=LR_MUON,\n",
        "  weight_decay=WD_MUON,\n",
        "  momentum=MOM_MUON,\n",
        "  nesterov=True,\n",
        "  adjust_lr_fn=\"match_rms_adamw\"\n",
        ")\n",
        "opt_adamw = optim.AdamW(\n",
        "    adamw_params,\n",
        "    lr=LR_ADAMW,\n",
        "    weight_decay=WD_ADAMW\n",
        "  )\n",
        "\n",
        "sch_muon = optim.lr_scheduler.CosineAnnealingLR(opt_muon, T_max=EPOCHS)\n",
        "sch_other = optim.lr_scheduler.CosineAnnealingLR(opt_adamw, T_max=EPOCHS)\n",
        "\n",
        "scaler = torch.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "tr5JgpzdtKXf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch_muon(model, loader, opt_muon, opt_other, scaler, criterion):\n",
        "  model.train()\n",
        "  total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "\n",
        "  for x, y in loader:\n",
        "    x = x.to(device, non_blocking=True)\n",
        "    y = y.to(device, non_blocking=True)\n",
        "\n",
        "    opt_muon.zero_grad(set_to_none=True)\n",
        "    opt_other.zero_grad(set_to_none=True)\n",
        "\n",
        "    with torch.autocast(device_type=device, dtype=torch.float16, enabled=(device==\"cuda\")):\n",
        "      logits = model(x)\n",
        "      loss = criterion(logits, y)\n",
        "\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(opt_muon)\n",
        "    scaler.step(opt_other)\n",
        "    scaler.update()\n",
        "\n",
        "    bs = x.size(0)\n",
        "    total_loss += loss.item() * bs\n",
        "    total_acc  += (logits.argmax(1) == y).float().sum().item()\n",
        "    n += bs\n",
        "\n",
        "  return total_loss / n, total_acc / n"
      ],
      "metadata": {
        "id": "S4hBFusJ5sMx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "patience = 5  # Stop after 5 epochs w/ no meaningful improvement\n",
        "bad_epochs = 0\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  train_loss, train_acc = train_one_epoch_muon(\n",
        "      model,\n",
        "      train_loader,\n",
        "      opt_muon,\n",
        "      opt_adamw,\n",
        "      scaler,\n",
        "      criterion\n",
        "  )\n",
        "  test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "  sch_muon.step()\n",
        "  sch_other.step()\n",
        "\n",
        "  print(f\"Epoch {epoch} | \"\n",
        "        f\"Train Loss {train_loss:.4f}, Train Accuracy {train_acc:.4f} | \"\n",
        "        f\"Test Loss {test_loss:.4f}, Test Accuracy {test_acc:.4f}\")\n",
        "\n",
        "  if test_acc > best_acc:\n",
        "    best_acc = test_acc\n",
        "    bad_epochs = 0\n",
        "    torch.save(model.state_dict(), \"vit_cifar100_best_muon.pt\")\n",
        "  else:\n",
        "    bad_epochs += 1\n",
        "    if bad_epochs >= patience:\n",
        "      print(f\"Early stopping at epoch {epoch}. Best Test Accuracy: {best_acc:.4f}\")\n",
        "      break\n",
        "\n",
        "print(\"Best Test Accuracy:\", best_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhq-NjQ65ylB",
        "outputId": "c75b7c15-92ac-446f-d72c-71ee4a278aac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss 3.9198, Train Accuracy 0.1045 | Test Loss 3.4552, Test Accuracy 0.1802\n",
            "Epoch 2 | Train Loss 3.2229, Train Accuracy 0.2136 | Test Loss 2.9700, Test Accuracy 0.2647\n",
            "Epoch 3 | Train Loss 2.8142, Train Accuracy 0.2850 | Test Loss 2.6394, Test Accuracy 0.3226\n",
            "Epoch 4 | Train Loss 2.5340, Train Accuracy 0.3440 | Test Loss 2.3993, Test Accuracy 0.3780\n",
            "Epoch 5 | Train Loss 2.3101, Train Accuracy 0.3885 | Test Loss 2.2471, Test Accuracy 0.4044\n",
            "Epoch 6 | Train Loss 2.1254, Train Accuracy 0.4286 | Test Loss 2.1298, Test Accuracy 0.4307\n",
            "Epoch 7 | Train Loss 1.9541, Train Accuracy 0.4652 | Test Loss 2.0005, Test Accuracy 0.4659\n",
            "Epoch 8 | Train Loss 1.8060, Train Accuracy 0.5009 | Test Loss 1.9028, Test Accuracy 0.4852\n",
            "Epoch 9 | Train Loss 1.6658, Train Accuracy 0.5336 | Test Loss 1.8177, Test Accuracy 0.5055\n",
            "Epoch 10 | Train Loss 1.5351, Train Accuracy 0.5681 | Test Loss 1.7778, Test Accuracy 0.5192\n",
            "Epoch 11 | Train Loss 1.4111, Train Accuracy 0.5984 | Test Loss 1.7541, Test Accuracy 0.5316\n",
            "Epoch 12 | Train Loss 1.2929, Train Accuracy 0.6288 | Test Loss 1.7090, Test Accuracy 0.5364\n",
            "Epoch 13 | Train Loss 1.1943, Train Accuracy 0.6549 | Test Loss 1.6839, Test Accuracy 0.5492\n",
            "Epoch 14 | Train Loss 1.1014, Train Accuracy 0.6811 | Test Loss 1.6820, Test Accuracy 0.5525\n",
            "Epoch 15 | Train Loss 1.0267, Train Accuracy 0.7021 | Test Loss 1.6755, Test Accuracy 0.5598\n",
            "Epoch 16 | Train Loss 0.9584, Train Accuracy 0.7197 | Test Loss 1.6751, Test Accuracy 0.5572\n",
            "Epoch 17 | Train Loss 0.9021, Train Accuracy 0.7361 | Test Loss 1.6656, Test Accuracy 0.5633\n",
            "Epoch 18 | Train Loss 0.8658, Train Accuracy 0.7491 | Test Loss 1.6585, Test Accuracy 0.5646\n",
            "Epoch 19 | Train Loss 0.8330, Train Accuracy 0.7581 | Test Loss 1.6549, Test Accuracy 0.5669\n",
            "Epoch 20 | Train Loss 0.8260, Train Accuracy 0.7621 | Test Loss 1.6545, Test Accuracy 0.5667\n",
            "Best Test Accuracy: 0.5669\n"
          ]
        }
      ]
    }
  ]
}